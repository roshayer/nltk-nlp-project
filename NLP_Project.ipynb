{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a41f21",
   "metadata": {},
   "source": [
    "# Natural Language Processing Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb9b0b",
   "metadata": {},
   "source": [
    "# TASK 1: GATHERING REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "722e796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_desc = pd.read_csv(\"MyAppDescriptions.csv\")\n",
    "df_feat = pd.read_csv(\"MyAppFeatures.csv\")\n",
    "\n",
    "#Five files \n",
    "df_regex = pd.read_csv(\"com.phikal.regex.csv\")\n",
    "df_cali = pd.read_csv(\"org.geometerplus.fbreader.plugin.local_opds_scanner.csv\")\n",
    "df_tube = pd.read_csv(\"free.rm.skytube.oss.csv\")\n",
    "df_grey = pd.read_csv(\"it.lucci.cm.greyscaletheme.csv\")\n",
    "df_flood = pd.read_csv(\"com.gunshippenguin.openflood.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6903b0",
   "metadata": {},
   "source": [
    "# TASK 2: PREPROCESSING THE TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39366704",
   "metadata": {},
   "source": [
    "Pre-Processing: Code Snippet & 15 Pre-processed Reviews (outputted) for each set of reviews (5 sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed717ef5",
   "metadata": {},
   "source": [
    "Column 'cleanText' denotes the preprocessed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "bd6c12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import num2words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence=sentence.replace(r'[^\\w\\s]+', \"\") #punctuation\n",
    "    sentence = sentence.lower() #Lowercase\n",
    "    sentence=sentence.replace('{html}',\"\") #\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df_regex['cleanText']=df_regex['review'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "09c69a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>reviewer name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>semicodin no.cache</td>\n",
       "      <td>Pathetic.</td>\n",
       "      <td>1</td>\n",
       "      <td>pathetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Kees de Koster</td>\n",
       "      <td>Nice, simple, useful!</td>\n",
       "      <td>5</td>\n",
       "      <td>nice simple useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>bill gannon</td>\n",
       "      <td>I was looking for a simple, intuitive regex ge...</td>\n",
       "      <td>5</td>\n",
       "      <td>looking simple intuitive regex generator check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Kneel B</td>\n",
       "      <td>Excellent app! Already know regex, but this wi...</td>\n",
       "      <td>5</td>\n",
       "      <td>excellent app already know regex help spot mis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>George Tzikas</td>\n",
       "      <td>Very basic. Flags don't work. No dark theme.</td>\n",
       "      <td>3</td>\n",
       "      <td>basic flags work dark theme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Mukesh Singh</td>\n",
       "      <td>Best app, thanks</td>\n",
       "      <td>5</td>\n",
       "      <td>best app thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>niobe trinity</td>\n",
       "      <td>Refreshing my memory on regex and found this w...</td>\n",
       "      <td>5</td>\n",
       "      <td>refreshing memory regex found well designed ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>John Kellum</td>\n",
       "      <td>Beautiful.</td>\n",
       "      <td>5</td>\n",
       "      <td>beautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>androiD Account</td>\n",
       "      <td>Very useful.. thanx...</td>\n",
       "      <td>5</td>\n",
       "      <td>useful thanx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Abhishek M</td>\n",
       "      <td>Thanks, really helpful.</td>\n",
       "      <td>5</td>\n",
       "      <td>thanks really helpful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Shemyaza</td>\n",
       "      <td>Nice for learning.</td>\n",
       "      <td>5</td>\n",
       "      <td>nice learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Александр Киселев</td>\n",
       "      <td>Useful tool</td>\n",
       "      <td>5</td>\n",
       "      <td>useful tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Jerry Nwosu</td>\n",
       "      <td>Wow! This is awesome</td>\n",
       "      <td>5</td>\n",
       "      <td>wow awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Jonas N</td>\n",
       "      <td>five stars if missing funktion flags is implem...</td>\n",
       "      <td>4</td>\n",
       "      <td>five stars missing funktion flags implemented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Matt H</td>\n",
       "      <td>I know regex already but had to give review se...</td>\n",
       "      <td>5</td>\n",
       "      <td>know regex already give review seeing clever s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           package name       reviewer name  \\\n",
       "0   net.takoli.regexgen  semicodin no.cache   \n",
       "1   net.takoli.regexgen      Kees de Koster   \n",
       "2   net.takoli.regexgen         bill gannon   \n",
       "3   net.takoli.regexgen             Kneel B   \n",
       "4   net.takoli.regexgen       George Tzikas   \n",
       "5   net.takoli.regexgen        Mukesh Singh   \n",
       "6   net.takoli.regexgen       niobe trinity   \n",
       "7   net.takoli.regexgen         John Kellum   \n",
       "8   net.takoli.regexgen     androiD Account   \n",
       "9   net.takoli.regexgen          Abhishek M   \n",
       "10  net.takoli.regexgen            Shemyaza   \n",
       "11  net.takoli.regexgen   Александр Киселев   \n",
       "12  net.takoli.regexgen         Jerry Nwosu   \n",
       "13  net.takoli.regexgen             Jonas N   \n",
       "14  net.takoli.regexgen              Matt H   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0                                           Pathetic.       1   \n",
       "1                               Nice, simple, useful!       5   \n",
       "2   I was looking for a simple, intuitive regex ge...       5   \n",
       "3   Excellent app! Already know regex, but this wi...       5   \n",
       "4        Very basic. Flags don't work. No dark theme.       3   \n",
       "5                                    Best app, thanks       5   \n",
       "6   Refreshing my memory on regex and found this w...       5   \n",
       "7                                          Beautiful.       5   \n",
       "8                              Very useful.. thanx...       5   \n",
       "9                             Thanks, really helpful.       5   \n",
       "10                                 Nice for learning.       5   \n",
       "11                                        Useful tool       5   \n",
       "12                               Wow! This is awesome       5   \n",
       "13  five stars if missing funktion flags is implem...       4   \n",
       "14  I know regex already but had to give review se...       5   \n",
       "\n",
       "                                            cleanText  \n",
       "0                                            pathetic  \n",
       "1                                  nice simple useful  \n",
       "2   looking simple intuitive regex generator check...  \n",
       "3   excellent app already know regex help spot mis...  \n",
       "4                         basic flags work dark theme  \n",
       "5                                     best app thanks  \n",
       "6   refreshing memory regex found well designed ea...  \n",
       "7                                           beautiful  \n",
       "8                                        useful thanx  \n",
       "9                               thanks really helpful  \n",
       "10                                      nice learning  \n",
       "11                                        useful tool  \n",
       "12                                        wow awesome  \n",
       "13      five stars missing funktion flags implemented  \n",
       "14  know regex already give review seeing clever s...  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regex.head(15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d597cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import num2words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence=sentence.replace(r'[^\\w\\s]+', \"\") \n",
    "    sentence = sentence.lower() \n",
    "    sentence=sentence.replace('{html}',\"\") #\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df_cali['cleanText']=df_cali['review'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ad4874a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>reviewer name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Lester Wilson</td>\n",
       "      <td>It works</td>\n",
       "      <td>4</td>\n",
       "      <td>works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>ABJ photography &amp; video</td>\n",
       "      <td>Works great with FBreader premium on my Androi...</td>\n",
       "      <td>4</td>\n",
       "      <td>works great fbreader premium android tablet an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Aastha Rani</td>\n",
       "      <td>ehttyy F tu ko</td>\n",
       "      <td>5</td>\n",
       "      <td>ehttyy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Julian Hughes</td>\n",
       "      <td>I just tried it on one device running Android ...</td>\n",
       "      <td>5</td>\n",
       "      <td>tried one device running android pie device ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Joe Bennett</td>\n",
       "      <td>Used to work great until Android 10 now won't ...</td>\n",
       "      <td>5</td>\n",
       "      <td>used work great android connect calibre host u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>debra ferrell</td>\n",
       "      <td>When I tried to open it, I got a message that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>tried open got message app older version fbrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Hwa Shi-Hsia</td>\n",
       "      <td>Doesn't work. Error message \"No catalogs found...</td>\n",
       "      <td>1</td>\n",
       "      <td>work error message catalogs found sorry phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Richard Hakes</td>\n",
       "      <td>I had problems with this and eventually found ...</td>\n",
       "      <td>5</td>\n",
       "      <td>problems eventually found simple solution need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Lelouch Lamperouge</td>\n",
       "      <td>How I am supposed to use this???</td>\n",
       "      <td>1</td>\n",
       "      <td>supposed use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Mohammed Rida Louhibi</td>\n",
       "      <td>No open button, no icône anywhere !</td>\n",
       "      <td>1</td>\n",
       "      <td>open button icône anywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>John Anderson</td>\n",
       "      <td>Says it installs, but there is no Open button,...</td>\n",
       "      <td>1</td>\n",
       "      <td>says installs open button app anywhere phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Cris &amp; Meg Dean</td>\n",
       "      <td>It's ok. Useful but...the thumbnails are so sm...</td>\n",
       "      <td>3</td>\n",
       "      <td>useful thumbnails small cannot see far unable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Hjrlrr Kindle</td>\n",
       "      <td>love it</td>\n",
       "      <td>4</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>Stephen S</td>\n",
       "      <td>does not work</td>\n",
       "      <td>1</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>org.geometerplus.fbreader.plugin.local_opds_sc...</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>This plug in works perfectly. It allows me to ...</td>\n",
       "      <td>5</td>\n",
       "      <td>plug works perfectly allows read book calibre ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         package name  \\\n",
       "0   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "1   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "2   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "3   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "4   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "5   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "6   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "7   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "8   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "9   org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "10  org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "11  org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "12  org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "13  org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "14  org.geometerplus.fbreader.plugin.local_opds_sc...   \n",
       "\n",
       "              reviewer name  \\\n",
       "0             Lester Wilson   \n",
       "1   ABJ photography & video   \n",
       "2               Aastha Rani   \n",
       "3             Julian Hughes   \n",
       "4               Joe Bennett   \n",
       "5             debra ferrell   \n",
       "6              Hwa Shi-Hsia   \n",
       "7             Richard Hakes   \n",
       "8        Lelouch Lamperouge   \n",
       "9     Mohammed Rida Louhibi   \n",
       "10            John Anderson   \n",
       "11          Cris & Meg Dean   \n",
       "12            Hjrlrr Kindle   \n",
       "13                Stephen S   \n",
       "14            A Google user   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0                                            It works       4   \n",
       "1   Works great with FBreader premium on my Androi...       4   \n",
       "2                                      ehttyy F tu ko       5   \n",
       "3   I just tried it on one device running Android ...       5   \n",
       "4   Used to work great until Android 10 now won't ...       5   \n",
       "5   When I tried to open it, I got a message that ...       1   \n",
       "6   Doesn't work. Error message \"No catalogs found...       1   \n",
       "7   I had problems with this and eventually found ...       5   \n",
       "8                    How I am supposed to use this???       1   \n",
       "9                 No open button, no icône anywhere !       1   \n",
       "10  Says it installs, but there is no Open button,...       1   \n",
       "11  It's ok. Useful but...the thumbnails are so sm...       3   \n",
       "12                                            love it       4   \n",
       "13                                      does not work       1   \n",
       "14  This plug in works perfectly. It allows me to ...       5   \n",
       "\n",
       "                                            cleanText  \n",
       "0                                               works  \n",
       "1   works great fbreader premium android tablet an...  \n",
       "2                                              ehttyy  \n",
       "3   tried one device running android pie device ru...  \n",
       "4   used work great android connect calibre host u...  \n",
       "5   tried open got message app older version fbrea...  \n",
       "6   work error message catalogs found sorry phone ...  \n",
       "7   problems eventually found simple solution need...  \n",
       "8                                        supposed use  \n",
       "9                          open button icône anywhere  \n",
       "10       says installs open button app anywhere phone  \n",
       "11  useful thumbnails small cannot see far unable ...  \n",
       "12                                               love  \n",
       "13                                               work  \n",
       "14  plug works perfectly allows read book calibre ...  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cali.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5ec386d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import num2words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence=sentence.replace(r'[^\\w\\s]+', \"\") \n",
    "    sentence = sentence.lower() \n",
    "    sentence=sentence.replace('{html}',\"\") #\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df_tube['cleanText']=df_tube['review'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6600be91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>reviewer name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Shylaja K</td>\n",
       "      <td>So much adds its not good just better update y...</td>\n",
       "      <td>3</td>\n",
       "      <td>much adds good better update playtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Addai Victoria</td>\n",
       "      <td>I really like this app</td>\n",
       "      <td>5</td>\n",
       "      <td>really like app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>firas alsaraheen</td>\n",
       "      <td>A very good alternative for youtube</td>\n",
       "      <td>4</td>\n",
       "      <td>good alternative youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Ifan Jones</td>\n",
       "      <td>It would be better if you could download the v...</td>\n",
       "      <td>4</td>\n",
       "      <td>would better could download videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Anwar Hossain</td>\n",
       "      <td>Utube</td>\n",
       "      <td>5</td>\n",
       "      <td>utube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Tajinder Singh Deol</td>\n",
       "      <td>Greatest App Store</td>\n",
       "      <td>5</td>\n",
       "      <td>greatest app store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Violet Moreno</td>\n",
       "      <td>Fun</td>\n",
       "      <td>5</td>\n",
       "      <td>fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>ALKESH_11 pawar</td>\n",
       "      <td>This is very good</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Kasan Williams</td>\n",
       "      <td>way better than YouTube YouTube dose not even ...</td>\n",
       "      <td>5</td>\n",
       "      <td>way better youtube youtube dose even work righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Christian caceres</td>\n",
       "      <td>Very good</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Suresh Tiwari</td>\n",
       "      <td>Kk</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>SIMMT Aholelei</td>\n",
       "      <td>Not working</td>\n",
       "      <td>1</td>\n",
       "      <td>working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Kuldip Kaur</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>5</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>RED FF YT AJIN</td>\n",
       "      <td>Not play stor no doweled</td>\n",
       "      <td>1</td>\n",
       "      <td>play stor doweled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>com.playsmusi.tubi2</td>\n",
       "      <td>Samaira Mir</td>\n",
       "      <td>Amazing application for watching videos and hd...</td>\n",
       "      <td>5</td>\n",
       "      <td>amazing application watching videos movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           package name        reviewer name  \\\n",
       "0   com.playsmusi.tubi2            Shylaja K   \n",
       "1   com.playsmusi.tubi2       Addai Victoria   \n",
       "2   com.playsmusi.tubi2     firas alsaraheen   \n",
       "3   com.playsmusi.tubi2           Ifan Jones   \n",
       "4   com.playsmusi.tubi2        Anwar Hossain   \n",
       "5   com.playsmusi.tubi2  Tajinder Singh Deol   \n",
       "6   com.playsmusi.tubi2        Violet Moreno   \n",
       "7   com.playsmusi.tubi2      ALKESH_11 pawar   \n",
       "8   com.playsmusi.tubi2       Kasan Williams   \n",
       "9   com.playsmusi.tubi2    Christian caceres   \n",
       "10  com.playsmusi.tubi2        Suresh Tiwari   \n",
       "11  com.playsmusi.tubi2       SIMMT Aholelei   \n",
       "12  com.playsmusi.tubi2          Kuldip Kaur   \n",
       "13  com.playsmusi.tubi2       RED FF YT AJIN   \n",
       "14  com.playsmusi.tubi2          Samaira Mir   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0   So much adds its not good just better update y...       3   \n",
       "1                              I really like this app       5   \n",
       "2                 A very good alternative for youtube       4   \n",
       "3   It would be better if you could download the v...       4   \n",
       "4                                               Utube       5   \n",
       "5                                  Greatest App Store       5   \n",
       "6                                                 Fun       5   \n",
       "7                                   This is very good       5   \n",
       "8   way better than YouTube YouTube dose not even ...       5   \n",
       "9                                           Very good       5   \n",
       "10                                                 Kk       5   \n",
       "11                                        Not working       1   \n",
       "12                                               GOOD       5   \n",
       "13                           Not play stor no doweled       1   \n",
       "14  Amazing application for watching videos and hd...       5   \n",
       "\n",
       "                                            cleanText  \n",
       "0               much adds good better update playtube  \n",
       "1                                     really like app  \n",
       "2                            good alternative youtube  \n",
       "3                  would better could download videos  \n",
       "4                                               utube  \n",
       "5                                  greatest app store  \n",
       "6                                                 fun  \n",
       "7                                                good  \n",
       "8   way better youtube youtube dose even work righ...  \n",
       "9                                                good  \n",
       "10                                                     \n",
       "11                                            working  \n",
       "12                                               good  \n",
       "13                                  play stor doweled  \n",
       "14         amazing application watching videos movies  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tube.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "72567f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import num2words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence=sentence.replace(r'[^\\w\\s]+', \"\")\n",
    "    sentence = sentence.lower() \n",
    "    sentence=sentence.replace('{html}',\"\") #\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df_grey['cleanText']=df_grey['review'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "22729ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>reviewer name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Long Dinh</td>\n",
       "      <td>Great theme</td>\n",
       "      <td>5</td>\n",
       "      <td>great theme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Mohamed Shadhaan</td>\n",
       "      <td>Best cm theme so far. Needs an update soon. So...</td>\n",
       "      <td>4</td>\n",
       "      <td>best theme far needs update soon apps got scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Ryan Stonecipher</td>\n",
       "      <td>This theme tweaks the default appearance of CM...</td>\n",
       "      <td>5</td>\n",
       "      <td>theme tweaks default appearance without going ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Doc 65</td>\n",
       "      <td>Is it compatible with Android N ?</td>\n",
       "      <td>5</td>\n",
       "      <td>compatible android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>areeb1296</td>\n",
       "      <td>Great theme. Just change the notifications and...</td>\n",
       "      <td>4</td>\n",
       "      <td>great theme change notifications quick setting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Nitin Sharma</td>\n",
       "      <td>Grey scale icons please</td>\n",
       "      <td>3</td>\n",
       "      <td>grey scale icons please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Faizal Ahmad</td>\n",
       "      <td>its a great theme</td>\n",
       "      <td>5</td>\n",
       "      <td>great theme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>ajitesh rai</td>\n",
       "      <td>Awesome theme, and very snappy too.</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome theme snappy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>petri voges</td>\n",
       "      <td>Its almost the best theme in the world.</td>\n",
       "      <td>4</td>\n",
       "      <td>almost best theme world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Nguyễn Huy Anh</td>\n",
       "      <td>That's I need</td>\n",
       "      <td>5</td>\n",
       "      <td>need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Tanay Singh</td>\n",
       "      <td>can you change the notification tiles(cards) l...</td>\n",
       "      <td>5</td>\n",
       "      <td>change notification tiles cards like android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>TJ</td>\n",
       "      <td>You can't go wrong with black &amp; white ;)</td>\n",
       "      <td>5</td>\n",
       "      <td>wrong black white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Erick Gamiz</td>\n",
       "      <td>Can't see the letters in the settings list scr...</td>\n",
       "      <td>4</td>\n",
       "      <td>see letters settings list screen letters white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Sơn Nguyễn</td>\n",
       "      <td>This is the simplest theme and makes my phone ...</td>\n",
       "      <td>5</td>\n",
       "      <td>simplest theme makes phone runs faster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>it.lucci.cm.greyscaletheme</td>\n",
       "      <td>Fran Poje</td>\n",
       "      <td>This theme is pure perfection. I've been using...</td>\n",
       "      <td>5</td>\n",
       "      <td>theme pure perfection using long time continue...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  package name     reviewer name  \\\n",
       "0   it.lucci.cm.greyscaletheme         Long Dinh   \n",
       "1   it.lucci.cm.greyscaletheme  Mohamed Shadhaan   \n",
       "2   it.lucci.cm.greyscaletheme  Ryan Stonecipher   \n",
       "3   it.lucci.cm.greyscaletheme            Doc 65   \n",
       "4   it.lucci.cm.greyscaletheme         areeb1296   \n",
       "5   it.lucci.cm.greyscaletheme      Nitin Sharma   \n",
       "6   it.lucci.cm.greyscaletheme      Faizal Ahmad   \n",
       "7   it.lucci.cm.greyscaletheme       ajitesh rai   \n",
       "8   it.lucci.cm.greyscaletheme       petri voges   \n",
       "9   it.lucci.cm.greyscaletheme    Nguyễn Huy Anh   \n",
       "10  it.lucci.cm.greyscaletheme       Tanay Singh   \n",
       "11  it.lucci.cm.greyscaletheme                TJ   \n",
       "12  it.lucci.cm.greyscaletheme       Erick Gamiz   \n",
       "13  it.lucci.cm.greyscaletheme        Sơn Nguyễn   \n",
       "14  it.lucci.cm.greyscaletheme         Fran Poje   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0                                         Great theme       5   \n",
       "1   Best cm theme so far. Needs an update soon. So...       4   \n",
       "2   This theme tweaks the default appearance of CM...       5   \n",
       "3                   Is it compatible with Android N ?       5   \n",
       "4   Great theme. Just change the notifications and...       4   \n",
       "5                             Grey scale icons please       3   \n",
       "6                                   its a great theme       5   \n",
       "7                 Awesome theme, and very snappy too.       5   \n",
       "8             Its almost the best theme in the world.       4   \n",
       "9                                       That's I need       5   \n",
       "10  can you change the notification tiles(cards) l...       5   \n",
       "11           You can't go wrong with black & white ;)       5   \n",
       "12  Can't see the letters in the settings list scr...       4   \n",
       "13  This is the simplest theme and makes my phone ...       5   \n",
       "14  This theme is pure perfection. I've been using...       5   \n",
       "\n",
       "                                            cleanText  \n",
       "0                                         great theme  \n",
       "1   best theme far needs update soon apps got scre...  \n",
       "2   theme tweaks default appearance without going ...  \n",
       "3                                  compatible android  \n",
       "4   great theme change notifications quick setting...  \n",
       "5                             grey scale icons please  \n",
       "6                                         great theme  \n",
       "7                                awesome theme snappy  \n",
       "8                             almost best theme world  \n",
       "9                                                need  \n",
       "10       change notification tiles cards like android  \n",
       "11                                  wrong black white  \n",
       "12  see letters settings list screen letters white...  \n",
       "13             simplest theme makes phone runs faster  \n",
       "14  theme pure perfection using long time continue...  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grey.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6b7e84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import num2words \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence=sentence.replace(r'[^\\w\\s]+', \"\") \n",
    "    sentence = sentence.lower() \n",
    "    sentence=sentence.replace('{html}',\"\") #\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df_flood['cleanText']=df_flood['review'].map(lambda s:preprocess(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5918a264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>reviewer name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Arian Gh</td>\n",
       "      <td>The best things in life are completely free!</td>\n",
       "      <td>5</td>\n",
       "      <td>best things life completely free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Kathleen Smith</td>\n",
       "      <td>Cannot replay favorite games. Wont allow paste...</td>\n",
       "      <td>2</td>\n",
       "      <td>cannot replay favorite games wont allow paste ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Joo Dee</td>\n",
       "      <td>This is a fun game. I like no ads and open sou...</td>\n",
       "      <td>4</td>\n",
       "      <td>fun game like ads open source managed win however</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Bryan Suandoko</td>\n",
       "      <td>I don't know how. But I'm addicted to this sim...</td>\n",
       "      <td>5</td>\n",
       "      <td>know addicted simple game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Fuwazu</td>\n",
       "      <td>It makes me think, and i failed twice 🤣 exactl...</td>\n",
       "      <td>5</td>\n",
       "      <td>makes think failed twice exactly need simple s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>George Murga</td>\n",
       "      <td>Very addictive! Easy to play, hard to solve. I...</td>\n",
       "      <td>5</td>\n",
       "      <td>addictive easy play hard solve like thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Matt Quinn</td>\n",
       "      <td>Great game</td>\n",
       "      <td>5</td>\n",
       "      <td>great game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Nader Taghinia</td>\n",
       "      <td>Very well written, addictive, smooth and witho...</td>\n",
       "      <td>5</td>\n",
       "      <td>well written addictive smooth without ads grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>dreamy stone</td>\n",
       "      <td>Great time waster, with zero ads. Definitely r...</td>\n",
       "      <td>5</td>\n",
       "      <td>great time waster zero ads definitely recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>don't give you a chance to finish getting your...</td>\n",
       "      <td>1</td>\n",
       "      <td>give chance finish getting color box one star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Ian Abbott</td>\n",
       "      <td>This is a nice little puzzle game which is bas...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice little puzzle game basically flood annoyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Frank Poth</td>\n",
       "      <td>This is a great little puzzle game. Check out ...</td>\n",
       "      <td>4</td>\n",
       "      <td>great little puzzle game check review pog vlog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Mohsin Siraj</td>\n",
       "      <td>Addicted</td>\n",
       "      <td>5</td>\n",
       "      <td>addicted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Jason Pham</td>\n",
       "      <td>Great game!</td>\n",
       "      <td>5</td>\n",
       "      <td>great game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>com.gunshippenguin.openflood</td>\n",
       "      <td>Drew Young</td>\n",
       "      <td>Dev has updated it a bunch and I like it even ...</td>\n",
       "      <td>5</td>\n",
       "      <td>dev updated bunch like even though seems alway...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    package name   reviewer name  \\\n",
       "0   com.gunshippenguin.openflood        Arian Gh   \n",
       "1   com.gunshippenguin.openflood  Kathleen Smith   \n",
       "2   com.gunshippenguin.openflood         Joo Dee   \n",
       "3   com.gunshippenguin.openflood  Bryan Suandoko   \n",
       "4   com.gunshippenguin.openflood          Fuwazu   \n",
       "5   com.gunshippenguin.openflood    George Murga   \n",
       "6   com.gunshippenguin.openflood      Matt Quinn   \n",
       "7   com.gunshippenguin.openflood  Nader Taghinia   \n",
       "8   com.gunshippenguin.openflood    dreamy stone   \n",
       "9   com.gunshippenguin.openflood   A Google user   \n",
       "10  com.gunshippenguin.openflood      Ian Abbott   \n",
       "11  com.gunshippenguin.openflood      Frank Poth   \n",
       "12  com.gunshippenguin.openflood    Mohsin Siraj   \n",
       "13  com.gunshippenguin.openflood      Jason Pham   \n",
       "14  com.gunshippenguin.openflood      Drew Young   \n",
       "\n",
       "                                               review  rating  \\\n",
       "0        The best things in life are completely free!       5   \n",
       "1   Cannot replay favorite games. Wont allow paste...       2   \n",
       "2   This is a fun game. I like no ads and open sou...       4   \n",
       "3   I don't know how. But I'm addicted to this sim...       5   \n",
       "4   It makes me think, and i failed twice 🤣 exactl...       5   \n",
       "5   Very addictive! Easy to play, hard to solve. I...       5   \n",
       "6                                          Great game       5   \n",
       "7   Very well written, addictive, smooth and witho...       5   \n",
       "8   Great time waster, with zero ads. Definitely r...       5   \n",
       "9   don't give you a chance to finish getting your...       1   \n",
       "10  This is a nice little puzzle game which is bas...       4   \n",
       "11  This is a great little puzzle game. Check out ...       4   \n",
       "12                                           Addicted       5   \n",
       "13                                        Great game!       5   \n",
       "14  Dev has updated it a bunch and I like it even ...       5   \n",
       "\n",
       "                                            cleanText  \n",
       "0                    best things life completely free  \n",
       "1   cannot replay favorite games wont allow paste ...  \n",
       "2   fun game like ads open source managed win however  \n",
       "3                           know addicted simple game  \n",
       "4   makes think failed twice exactly need simple s...  \n",
       "5           addictive easy play hard solve like thank  \n",
       "6                                          great game  \n",
       "7   well written addictive smooth without ads grea...  \n",
       "8     great time waster zero ads definitely recommend  \n",
       "9       give chance finish getting color box one star  \n",
       "10  nice little puzzle game basically flood annoyi...  \n",
       "11  great little puzzle game check review pog vlog...  \n",
       "12                                           addicted  \n",
       "13                                         great game  \n",
       "14  dev updated bunch like even though seems alway...  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flood.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f669e",
   "metadata": {},
   "source": [
    "# TASK 2: OPINION ON STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfc417",
   "metadata": {},
   "source": [
    "The choice of stopwords in NTLK certainly has an impact on the analysis of the reviews. Although stopwords are considered meaningless, they definitely create a vital impact in the process of data analysis. They make the process of elimination faster and easier. Elimination of stopwords help us remove information irrelevant to the actual information that needs to extracted. When there are too many words clustered together, stopwords' removal helps in deriving the important keywords. The risk behind using a non-customized list of stop words make it a little cumbersome to spot important keywords the user/reviewer is trying to convey. In case, the reviewer (stakeholder) uses layman terms instead of words related to the app, some other words that actually have meaning may get discarded. Suppose their primary language used for communication is not in English, they won't be able to convey what is needed where some common vocabulary might even get lost. The other pitfall I noticed with non-customized lists are that slangs don't get eliminated, making it difficult to extract keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92aa33b",
   "metadata": {},
   "source": [
    "# TASK 3: SENTIMENT ANALYSIS using VADER & TEXTBLOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388bd22",
   "metadata": {},
   "source": [
    "Code Snippet: Vader & TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6eaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4d92d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "36cba007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61663fa",
   "metadata": {},
   "source": [
    "Code Snippet Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7e649bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vader Score\n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "def vader_sentiment_scores(text):\n",
    "    score = vader_sentiment.polarity_scores(text)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabd8d5",
   "metadata": {},
   "source": [
    "Code Snippet TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2cc9e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TextBlob Score\n",
    "def textblob_sentiment_scores (text):\n",
    "    textblob_sentiment = TextBlob(text)\n",
    "    score = textblob_sentiment.polarity \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "fde73b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Vader & TextBlob\n",
    "\n",
    "df_regex['vaderText']=df_regex['cleanText'].map(lambda s:vader_sentiment_scores(s)) \n",
    "df_regex['textBlob']=df_regex['cleanText'].map(lambda s:textblob_sentiment_scores(s)) \n",
    "\n",
    "df_cali['vaderText']=df_cali['cleanText'].map(lambda s:vader_sentiment_scores(s)) \n",
    "df_cali['textBlob']=df_cali['cleanText'].map(lambda s:textblob_sentiment_scores(s)) \n",
    "\n",
    "df_tube['vaderText']=df_tube['cleanText'].map(lambda s:vader_sentiment_scores(s)) \n",
    "df_tube['textBlob']=df_tube['cleanText'].map(lambda s:textblob_sentiment_scores(s)) \n",
    "\n",
    "df_grey['vaderText']=df_grey['cleanText'].map(lambda s:vader_sentiment_scores(s)) \n",
    "df_grey['textBlob']=df_grey['cleanText'].map(lambda s:textblob_sentiment_scores(s)) \n",
    "\n",
    "df_flood['vaderText']=df_flood['cleanText'].map(lambda s:vader_sentiment_scores(s)) \n",
    "df_flood['textBlob']=df_flood['cleanText'].map(lambda s:textblob_sentiment_scores(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c2deb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity for both Vader & TextBlob\n",
    "def analysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7c6b3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regex['polarity_v']=df_regex['vaderText'].map(lambda s:analysis(s))\n",
    "df_cali['polarity_v']=df_cali['vaderText'].map(lambda s:analysis(s))\n",
    "df_tube['polarity_v']=df_tube['vaderText'].map(lambda s:analysis(s))\n",
    "df_grey['polarity_v']=df_grey['vaderText'].map(lambda s:analysis(s))\n",
    "df_flood['polarity_v']=df_flood['vaderText'].map(lambda s:analysis(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fe9a33c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regex['polarity_tb']=df_regex['textBlob'].map(lambda s:analysis(s))\n",
    "df_cali['polarity_tb']=df_cali['textBlob'].map(lambda s:analysis(s))\n",
    "df_tube['polarity_tb']=df_tube['textBlob'].map(lambda s:analysis(s))\n",
    "df_grey['polarity_tb']=df_grey['textBlob'].map(lambda s:analysis(s))\n",
    "df_flood['polarity_tb']=df_flood['textBlob'].map(lambda s:analysis(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b9965d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate all dataframes\n",
    "df_all_rows = pd.concat([df_regex, df_cali, df_tube, df_grey, df_flood])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a367cb",
   "metadata": {},
   "source": [
    "Output Table: Vader Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3791861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = df_all_rows[['package name', 'review', 'polarity_v']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "eac0d572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity_v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Pathetic.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Nice, simple, useful!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>I was looking for a simple, intuitive regex ge...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Excellent app! Already know regex, but this wi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Very basic. Flags don't work. No dark theme.</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Thank you, great app. Could do with a UI update.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>A good regex tester and dev tool. Intuitive us...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Excellent app! Very very convenient to use! Es...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                package name  \\\n",
       "0        net.takoli.regexgen   \n",
       "1        net.takoli.regexgen   \n",
       "2        net.takoli.regexgen   \n",
       "3        net.takoli.regexgen   \n",
       "4        net.takoli.regexgen   \n",
       "..                       ...   \n",
       "95  com.sevenbit.regexenator   \n",
       "96  com.sevenbit.regexenator   \n",
       "97  com.sevenbit.regexenator   \n",
       "98  com.sevenbit.regexenator   \n",
       "99  com.sevenbit.regexenator   \n",
       "\n",
       "                                               review polarity_v  \n",
       "0                                           Pathetic.   Negative  \n",
       "1                               Nice, simple, useful!   Positive  \n",
       "2   I was looking for a simple, intuitive regex ge...   Positive  \n",
       "3   Excellent app! Already know regex, but this wi...   Positive  \n",
       "4        Very basic. Flags don't work. No dark theme.    Neutral  \n",
       "..                                                ...        ...  \n",
       "95   Thank you, great app. Could do with a UI update.   Positive  \n",
       "96  A good regex tester and dev tool. Intuitive us...   Positive  \n",
       "97  Excellent app! Very very convenient to use! Es...   Positive  \n",
       "98                                            Awesome   Positive  \n",
       "99                                               Good   Positive  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vader.head(100)\n",
    "\n",
    "#In the table below I have displayed the actual 'review' column, not the preprocessed review ('cleanText') column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20901910",
   "metadata": {},
   "source": [
    "Output Table: Textblob Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7e4a9c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textblob = df_all_rows[['package name', 'review', 'polarity_tb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "311155f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package name</th>\n",
       "      <th>review</th>\n",
       "      <th>polarity_tb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Pathetic.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Nice, simple, useful!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>I was looking for a simple, intuitive regex ge...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Excellent app! Already know regex, but this wi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>net.takoli.regexgen</td>\n",
       "      <td>Very basic. Flags don't work. No dark theme.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Thank you, great app. Could do with a UI update.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>A good regex tester and dev tool. Intuitive us...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Excellent app! Very very convenient to use! Es...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>com.sevenbit.regexenator</td>\n",
       "      <td>Good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                package name  \\\n",
       "0        net.takoli.regexgen   \n",
       "1        net.takoli.regexgen   \n",
       "2        net.takoli.regexgen   \n",
       "3        net.takoli.regexgen   \n",
       "4        net.takoli.regexgen   \n",
       "..                       ...   \n",
       "95  com.sevenbit.regexenator   \n",
       "96  com.sevenbit.regexenator   \n",
       "97  com.sevenbit.regexenator   \n",
       "98  com.sevenbit.regexenator   \n",
       "99  com.sevenbit.regexenator   \n",
       "\n",
       "                                               review polarity_tb  \n",
       "0                                           Pathetic.    Negative  \n",
       "1                               Nice, simple, useful!    Positive  \n",
       "2   I was looking for a simple, intuitive regex ge...    Positive  \n",
       "3   Excellent app! Already know regex, but this wi...    Positive  \n",
       "4        Very basic. Flags don't work. No dark theme.    Negative  \n",
       "..                                                ...         ...  \n",
       "95   Thank you, great app. Could do with a UI update.    Positive  \n",
       "96  A good regex tester and dev tool. Intuitive us...    Positive  \n",
       "97  Excellent app! Very very convenient to use! Es...    Positive  \n",
       "98                                            Awesome    Positive  \n",
       "99                                               Good    Positive  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_textblob.head(100)\n",
    "\n",
    "#In the table below I have displayed the actual 'review' column, not the preprocessed review ('cleanText') column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c38548",
   "metadata": {},
   "source": [
    "Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1dd985",
   "metadata": {},
   "source": [
    "Vader & Textblob are the most commonly used sentiment analysis libraries. They both use the same lexicon based method that maps between words and sentiments. The sentiment of the each sentence is the aggregation of the sentiment of every term. Vader is highly focused on social media. As a result of this, Vader takes a lot of effort in figuring out the sentiments of the content that has a lot of emoticons, repeated terms and punctuations. TextBlob, on the other hand just looks at the sentence and extracts the sentiment. Vader provides more granular sentiment than TextBlob and considers repeated words important when evaluating the sentiment of the text.\n",
    "The best option for my apps' review analysis amongst the two is certainly TextBlob because it gives the accurate score regardless of change in repeated words. Vader would have been more accurate if I hadn't preprocessed the reviews because it considers repeated words, punctuations, emojis to have stronger sentiment as opposed to TextBlob. Although Vader outweighs TextBlob in many ways, for reviews like this (e.g. row 4), TextBlob gives an apt score than Vader based on the words. Vader considers it neutral due to the usage of informal language, but TextBlob calls it negative based on sentiment of the words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b6900",
   "metadata": {},
   "source": [
    "# TASK 4: TOPIC MODELING using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4b06",
   "metadata": {},
   "source": [
    "The app with the highest number of reviews from the set of assigned apps is FBCalibre. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c03e2",
   "metadata": {},
   "source": [
    "Topic Modelling: Code Snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2109379",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "89a4678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "dea8fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b949852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e5d09a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2940d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "6be4f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate function\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "44e6340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSIGNED APP\n",
    "\n",
    "df_assigned = df_cali.loc[df_cali['package name'] == 'org.geometerplus.fbreader.plugin.local_opds_scanner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "cc0e3fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assigned['lemma']=df_assigned['cleanText'].map(lambda s:lemmatize_stemming(s)) \n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "cf42a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df_assigned['lemma'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c0afdec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               [work]\n",
       "1    [work, great, fbreader, premium, android, tabl...\n",
       "2                                             [ehttyy]\n",
       "3    [tri, devic, run, android, devic, run, android...\n",
       "4    [work, great, android, connect, calibr, host, ...\n",
       "5    [tri, open, messag, older, version, fbreader, ...\n",
       "6    [work, error, messag, catalog, sorri, phone, c...\n",
       "7    [problem, eventu, simpl, solut, need, conect, ...\n",
       "8                                             [suppos]\n",
       "9                          [open, button, icôn, anywh]\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a6446022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 work\n",
      "1 android\n",
      "2 develop\n",
      "3 fbreader\n",
      "4 great\n",
      "5 messag\n",
      "6 older\n",
      "7 phone\n",
      "8 premium\n",
      "9 tablet\n",
      "10 time\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words on Review Set (ASSIGNED APP)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "4d5560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary \n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e698e60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "bb6fc6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "2d320379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.051*\"network\" + 0.041*\"local\" + 0.040*\"fbreader\" + 0.023*\"star\" + 0.022*\"plugin\" + 0.022*\"featur\" + 0.021*\"pain\" + 0.021*\"calibr\" + 0.021*\"major\" + 0.020*\"type\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.050*\"calibr\" + 0.050*\"book\" + 0.034*\"fbreader\" + 0.034*\"metadata\" + 0.029*\"work\" + 0.029*\"perfectli\" + 0.018*\"connect\" + 0.018*\"phone\" + 0.018*\"librari\" + 0.018*\"plug\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.038*\"fbreader\" + 0.035*\"updat\" + 0.033*\"version\" + 0.032*\"ebook\" + 0.032*\"devic\" + 0.032*\"reader\" + 0.028*\"awesom\" + 0.020*\"instal\" + 0.019*\"open\" + 0.018*\"tablet\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.027*\"work\" + 0.027*\"expect\" + 0.017*\"fbreader\" + 0.011*\"plugin\" + 0.011*\"instal\" + 0.010*\"epub\" + 0.010*\"nexu\" + 0.009*\"number\" + 0.009*\"download\" + 0.007*\"add\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.033*\"plugin\" + 0.033*\"instal\" + 0.029*\"download\" + 0.025*\"book\" + 0.019*\"calibr\" + 0.017*\"say\" + 0.015*\"number\" + 0.013*\"abl\" + 0.012*\"phone\" + 0.012*\"easi\"\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.062*\"love\" + 0.037*\"calibr\" + 0.021*\"know\" + 0.020*\"upgrad\" + 0.020*\"main\" + 0.020*\"djvu\" + 0.020*\"book\" + 0.019*\"need\" + 0.019*\"read\" + 0.019*\"prefer\"\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.067*\"work\" + 0.061*\"android\" + 0.050*\"calibr\" + 0.031*\"connect\" + 0.031*\"devic\" + 0.021*\"updat\" + 0.021*\"fbreader\" + 0.021*\"run\" + 0.021*\"host\" + 0.021*\"great\"\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.039*\"connect\" + 0.039*\"work\" + 0.027*\"lack\" + 0.021*\"messag\" + 0.021*\"catalog\" + 0.021*\"wifi\" + 0.021*\"simpl\" + 0.020*\"tablet\" + 0.020*\"calibr\" + 0.018*\"correct\"\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.052*\"server\" + 0.039*\"chang\" + 0.025*\"open\" + 0.024*\"button\" + 0.020*\"set\" + 0.020*\"unabl\" + 0.020*\"use\" + 0.020*\"small\" + 0.020*\"thumbnail\" + 0.020*\"icôn\"\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.068*\"fbreader\" + 0.040*\"epub\" + 0.040*\"nexu\" + 0.018*\"instal\" + 0.016*\"download\" + 0.016*\"خوبه\" + 0.015*\"downlad\" + 0.015*\"init\" + 0.015*\"charg\" + 0.015*\"mobil\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TOPICS FOR ASSIGNED APP using BoW\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print('')\n",
    "    \n",
    "#There are 10 topics below. Each topic has atleast 7 words describing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082330fe",
   "metadata": {},
   "source": [
    "Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc7139",
   "metadata": {},
   "source": [
    "The topics vary to the functionalities/features I extracted manually. The functionalities or the features I extracted from the app description were predominantly about what the app does, how the app has to be utilized, and what unique features the app contains. However, in this case, there are several topics belonging to different domains but somehow relating to the actual app. Each topic, if viewed separately (without connecting to the ASSIGNED APP), they might open up another new set of words that may be completely unrelated to the ASSIGNED APP and its features. The bigrams and tri-grams were also similar to the manually extracted functionalities/features because we are extracting them from the app descriptions only. The reviews have different facets of the ASSIGNED APP so, there are multiple topics connecting to various fields. The app description of an ASSIGNED APP solely revolves around the app, so commonalities between topic reviews and features is miniscule.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "8b9948f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Competitor & Similar Apps\n",
    "df_comsim1 = df_cali.loc[df_cali['package name'] == 'com.tonymaro.calibreLibrary.apk'] #Similar\n",
    "df_comsim2 = df_cali.loc[df_cali['package name'] == 'com.multipie.calibreandroid']\n",
    "df_comsim3 = df_cali.loc[df_cali['package name'] == 'com.amazon.kindle']\n",
    "df_comsim4 = df_cali.loc[df_cali['package name'] == 'org.readera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "37035895",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comsim1['lemma']=df_comsim1['cleanText'].map(lambda s:lemmatize_stemming(s)) \n",
    "df_comsim2['lemma']=df_comsim2['cleanText'].map(lambda s:lemmatize_stemming(s)) \n",
    "df_comsim3['lemma']=df_comsim3['cleanText'].map(lambda s:lemmatize_stemming(s)) \n",
    "df_comsim4['lemma']=df_comsim4['cleanText'].map(lambda s:lemmatize_stemming(s)) \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "df9c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs1 = df_comsim1['lemma'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "9569de2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44                                               [year]\n",
       "45                                               [work]\n",
       "46    [possibl, choos, download, locat, app, downloa...\n",
       "47    [updat, break, load, calibr, librari, tablet, ...\n",
       "48    [useless, longer, pick, download, directori, u...\n",
       "49    [perfect, companion, virtual, librari, calibr,...\n",
       "50    [sure, open, associ, ebook, format, download, ...\n",
       "51    [good, recent, updat, android, break, longer, ...\n",
       "52    [longer, specifi, book, directori, android, mo...\n",
       "53    [great, calibr, user, longer, specifi, downloa...\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "538bd657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 year\n",
      "1 work\n",
      "2 android\n",
      "3 app\n",
      "4 book\n",
      "5 choos\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words in Review Set (COMPETITOR & SIMILAR APPS)\n",
    "dictionary1 = gensim.corpora.Dictionary(processed_docs1)\n",
    "count = 0\n",
    "for k, v in dictionary1.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "11e9c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary1.doc2bow(doc) for doc in processed_docs1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3af23868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "67784de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary1, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bf24a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.040*\"calibr\" + 0.032*\"work\" + 0.022*\"book\" + 0.021*\"download\" + 0.018*\"librari\" + 0.012*\"reader\" + 0.011*\"search\" + 0.009*\"nexu\" + 0.009*\"file\" + 0.009*\"access\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.020*\"book\" + 0.014*\"librari\" + 0.013*\"folder\" + 0.013*\"star\" + 0.012*\"connect\" + 0.012*\"read\" + 0.012*\"calibr\" + 0.011*\"think\" + 0.010*\"author\" + 0.010*\"devic\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.031*\"great\" + 0.019*\"respons\" + 0.017*\"refund\" + 0.017*\"help\" + 0.017*\"librari\" + 0.016*\"access\" + 0.016*\"work\" + 0.013*\"connect\" + 0.012*\"develop\" + 0.011*\"love\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.056*\"download\" + 0.026*\"calibr\" + 0.025*\"book\" + 0.022*\"server\" + 0.018*\"librari\" + 0.015*\"sync\" + 0.012*\"specifi\" + 0.012*\"abil\" + 0.011*\"file\" + 0.011*\"opd\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.050*\"work\" + 0.030*\"great\" + 0.023*\"calibr\" + 0.018*\"problem\" + 0.015*\"easi\" + 0.014*\"librari\" + 0.012*\"worth\" + 0.012*\"network\" + 0.010*\"nook\" + 0.010*\"server\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TOPICS FOR SIMILAR APP (1st APP)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print(\"\")\n",
    "    \n",
    "#There are 5 topics below. Each topic has atleast 7 words describing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "5c414d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs2 = df_comsim2['lemma'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "a652373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143    [fulli, featur, work, properli, specifi, downl...\n",
       "144    [android, app, tri, thing, includ, public, add...\n",
       "145    [great, websit, read, document, say, critic, w...\n",
       "146                                      [nice, softwar]\n",
       "147    [help, android, phone, factori, reset, dropbox...\n",
       "148                                      [work, perfect]\n",
       "149    [develop, disappear, search, calibr, sync, sim...\n",
       "150                                               [work]\n",
       "151                [break, messi, manag, function, poor]\n",
       "152         [work, tri, connect, stick, authent, screen]\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ac9ad093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 brilliantli\n",
      "1 directori\n",
      "2 download\n",
      "3 easi\n",
      "4 featur\n",
      "5 fulli\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words in Review Set (COMPETITOR & SIMILAR APPS)\n",
    "dictionary2 = gensim.corpora.Dictionary(processed_docs2)\n",
    "count = 0\n",
    "for k, v in dictionary2.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "d82d89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary2.doc2bow(doc) for doc in processed_docs2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "417cbaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4189986889228802),\n",
      " (1, 0.3302181557942338),\n",
      " (2, 0.20574663967680878),\n",
      " (3, 0.15306902992835522),\n",
      " (4, 0.23549209999519846),\n",
      " (5, 0.3611024825669631),\n",
      " (6, 0.3137394546674454),\n",
      " (7, 0.38409376692540154),\n",
      " (8, 0.3993412562651903),\n",
      " (9, 0.15591654217052253),\n",
      " (10, 0.1844962174225812)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "dd9804e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary2, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "fcca9100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.066*\"chang\" + 0.024*\"money\" + 0.018*\"exhaust\" + 0.015*\"tech\" + 0.015*\"let\" + 0.013*\"wont\" + 0.012*\"work\" + 0.011*\"time\" + 0.011*\"chapter\" + 0.010*\"reli\"\n",
      " \n",
      "Topic: 1 \n",
      "Words: 0.081*\"exhaust\" + 0.051*\"money\" + 0.045*\"wont\" + 0.029*\"chang\" + 0.018*\"perfect\" + 0.017*\"let\" + 0.010*\"cabl\" + 0.010*\"gladli\" + 0.008*\"databas\" + 0.008*\"icon\"\n",
      " \n",
      "Topic: 2 \n",
      "Words: 0.102*\"chang\" + 0.070*\"exhaust\" + 0.035*\"wont\" + 0.035*\"brilliantli\" + 0.020*\"money\" + 0.018*\"work\" + 0.012*\"sell\" + 0.011*\"perfect\" + 0.009*\"fulli\" + 0.008*\"nice\"\n",
      " \n",
      "Topic: 3 \n",
      "Words: 0.053*\"chang\" + 0.036*\"wont\" + 0.031*\"perfect\" + 0.030*\"exhaust\" + 0.017*\"brilliantli\" + 0.017*\"damn\" + 0.016*\"wordpress\" + 0.014*\"sell\" + 0.012*\"nook\" + 0.012*\"appear\"\n",
      " \n",
      "Topic: 4 \n",
      "Words: 0.032*\"nice\" + 0.025*\"wont\" + 0.015*\"right\" + 0.014*\"fulli\" + 0.009*\"chang\" + 0.007*\"white\" + 0.006*\"awar\" + 0.006*\"entri\" + 0.006*\"password\" + 0.006*\"tech\"\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#TOPICS FOR COMPETITOR APP (2nd APP)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print (\" \")\n",
    "    \n",
    "#There are 5 topics below. Each topic has atleast 7 words describing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d06dbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs3 = df_comsim3['lemma'].map(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "49e47609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1524                                         [amaz, amaz]\n",
       "1525    [brilliant, read, beat, real, book, cours, kin...\n",
       "1526                                [wonder, love, stori]\n",
       "1527    [improv, like, audibl, record, disappear, rand...\n",
       "1528                 [wish, control, suggest, book, want]\n",
       "1529                                         [amaz, book]\n",
       "1530    [love, kindl, best, suppli, book, total, expen...\n",
       "1531                                               [nice]\n",
       "1532                                    [dogshit, german]\n",
       "1533          [lot, book, avail, free, easi, read, handi]\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "c831b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 amaz\n",
      "1 beat\n",
      "2 book\n",
      "3 brilliant\n",
      "4 close\n",
      "5 cours\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words in Review Set (COMPETITOR & SIMILAR APPS)\n",
    "dictionary3 = gensim.corpora.Dictionary(processed_docs3)\n",
    "count = 0\n",
    "for k, v in dictionary3.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f620607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary3.doc2bow(doc) for doc in processed_docs3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2fb5e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "3465d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary3, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "7100bbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.063*\"love\" + 0.057*\"avail\" + 0.051*\"caus\" + 0.035*\"read\" + 0.024*\"phone\" + 0.021*\"nice\" + 0.019*\"miss\" + 0.018*\"reliabl\" + 0.017*\"tablet\" + 0.014*\"long\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.091*\"amaz\" + 0.075*\"care\" + 0.019*\"avail\" + 0.018*\"love\" + 0.017*\"caus\" + 0.009*\"critic\" + 0.009*\"black\" + 0.009*\"nice\" + 0.008*\"amazon\" + 0.008*\"expens\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.094*\"avail\" + 0.042*\"love\" + 0.039*\"long\" + 0.028*\"imposs\" + 0.023*\"caus\" + 0.020*\"leav\" + 0.014*\"black\" + 0.014*\"horribl\" + 0.014*\"week\" + 0.013*\"seri\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.096*\"love\" + 0.084*\"avail\" + 0.074*\"caus\" + 0.043*\"long\" + 0.016*\"care\" + 0.013*\"concept\" + 0.012*\"delet\" + 0.012*\"name\" + 0.011*\"scrol\" + 0.009*\"amaz\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.047*\"dogshit\" + 0.042*\"avail\" + 0.032*\"cours\" + 0.022*\"size\" + 0.018*\"payment\" + 0.013*\"leav\" + 0.012*\"love\" + 0.011*\"darn\" + 0.010*\"add\" + 0.009*\"melhor\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TOPICS FOR COMPETITOR APP (3rd APP)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print('')\n",
    "    \n",
    "#There are 5 topics below. Each topic has atleast 7 words describing it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "d3199211",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs4 = df_comsim4['lemma'].map(preprocess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "67ed0a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2104                                               [good]\n",
       "2105    [like, option, review, theme, attract, tablet,...\n",
       "2106                                               [best]\n",
       "2107                      [excel, reader, basic, everyth]\n",
       "2108                                   [best, come, read]\n",
       "2109    [hand, absolut, best, reader, work, file, type...\n",
       "2110                                               [nice]\n",
       "2111                                               [good]\n",
       "2112    [simpl, effect, keep, book, grow, categor, eas...\n",
       "2113                                              [great]\n",
       "Name: lemma, dtype: object"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "9ffa5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 good\n",
      "1 aswel\n",
      "2 attract\n",
      "3 devic\n",
      "4 iphon\n",
      "5 like\n"
     ]
    }
   ],
   "source": [
    "#Bag of Words in Review Set (COMPETITOR & SIMILAR APPS)\n",
    "dictionary4 = gensim.corpora.Dictionary(processed_docs4)\n",
    "count = 0\n",
    "for k, v in dictionary4.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "249eea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary4.doc2bow(doc) for doc in processed_docs3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "70ef10df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(168, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "79b5564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=5, id2word=dictionary4, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "34669c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.042*\"book\" + 0.032*\"download\" + 0.026*\"excel\" + 0.019*\"kindl\" + 0.017*\"awesom\" + 0.015*\"time\" + 0.015*\"disappear\" + 0.014*\"give\" + 0.014*\"delet\" + 0.012*\"librari\"\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.109*\"read\" + 0.069*\"great\" + 0.063*\"book\" + 0.051*\"kindl\" + 0.021*\"work\" + 0.020*\"like\" + 0.017*\"love\" + 0.013*\"good\" + 0.012*\"want\" + 0.012*\"need\"\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.104*\"book\" + 0.062*\"love\" + 0.060*\"kindl\" + 0.033*\"good\" + 0.033*\"read\" + 0.016*\"amazon\" + 0.015*\"easi\" + 0.013*\"free\" + 0.011*\"librari\" + 0.011*\"work\"\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.074*\"read\" + 0.074*\"book\" + 0.029*\"nice\" + 0.027*\"kindl\" + 0.022*\"time\" + 0.020*\"good\" + 0.019*\"amaz\" + 0.017*\"best\" + 0.015*\"enjoy\" + 0.014*\"phone\"\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.029*\"download\" + 0.029*\"book\" + 0.017*\"load\" + 0.016*\"phone\" + 0.016*\"amazon\" + 0.016*\"access\" + 0.013*\"list\" + 0.013*\"updat\" + 0.012*\"googl\" + 0.012*\"free\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TOPICS FOR COMPETITOR APP (4th APP)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print('')\n",
    "    \n",
    "#There are 5 topics below. Each topic has atleast 7 words describing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2360c",
   "metadata": {},
   "source": [
    "The extracted topics of the COMPETITOR/SIMILAR APPS are quite similar to the ASSIGNED APP. There is atleast one common word for every topic between each COMPETITOR/SIMILAR APP to the ASSIGNED APP. For example words like 'work', 'read', 'book', 'love' are pretty common in most of the review topics. 'Calibr' was a common word between the ASSIGNED APP and the SIMILAR APP. The COMPETITOR APPS had 'work', 'book', 'love', 'calibre', and 'read' in common. As a result, these reviews topics show that my presumption of these apps to be the similar and competitor apps from Assignment 2 are almost right. The descriptions and the reviews have lots of topics in common. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d194b",
   "metadata": {},
   "source": [
    "# TASK 4: TOPICS with HIGHEST % CONTRIBUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca90667",
   "metadata": {},
   "source": [
    "The topics with the highest percentage contribution in the review are :\n",
    "\n",
    "1) network\n",
    "\n",
    "2) calibre\n",
    "\n",
    "3) fbreader\n",
    "\n",
    "4) work\n",
    "\n",
    "5) plugin\n",
    "\n",
    "6) love\n",
    "\n",
    "7) work\n",
    "\n",
    "8) connect\n",
    "\n",
    "9) server\n",
    "\n",
    "10) fbreader\n",
    "\n",
    "Since 'Work' and 'FBReader' were repetitive, I chose the next two with the highest percentage contribution. \n",
    "\n",
    "1) android\n",
    "\n",
    "2) book"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01772ed7",
   "metadata": {},
   "source": [
    "#Bag of Words on Review Set (ASSIGNED APP)\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "        \n",
    "#Dictionary \n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "#TOPICS FOR ASSIGNED APP using BoW\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    print('')\n",
    "    \n",
    "#There are 10 topics below. Each topic has atleast 7 words describing it. \n",
    "\n",
    "NOTE: The code is already written as a part of the actual TASK 4. So, I have copied the same code here as a markdown to prevent confusion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc11fe0",
   "metadata": {},
   "source": [
    "The list of 10 reviews of the ASSIGNED APP that developers must take into consideration are displayed below.\n",
    "\n",
    "The reviews with the lowest ratings are the best tools for developers to rebuild/fix their software and ensure that their apps are up-to-date and easier for the users to operate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "1e5a14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ten = df_cali.loc[df_cali['rating'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "2acc3013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = df_ten[['review', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a45bc6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When I tried to open it, I got a message that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Doesn't work. Error message \"No catalogs found...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How I am supposed to use this???</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>No open button, no icône anywhere !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Says it installs, but there is no Open button,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>does not work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Does not work. Nothing I did would make my tab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>It keeps asking for pluggings for everything...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>This plugin does not recognize ANY OPDS server...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>not working</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review  rating\n",
       "5   When I tried to open it, I got a message that ...       1\n",
       "6   Doesn't work. Error message \"No catalogs found...       1\n",
       "8                    How I am supposed to use this???       1\n",
       "9                 No open button, no icône anywhere !       1\n",
       "10  Says it installs, but there is no Open button,...       1\n",
       "13                                      does not work       1\n",
       "21  Does not work. Nothing I did would make my tab...       1\n",
       "28    It keeps asking for pluggings for everything...       1\n",
       "38  This plugin does not recognize ANY OPDS server...       1\n",
       "45                                        not working       1"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rev.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9ad10",
   "metadata": {},
   "source": [
    "# TASK 5: RECOMMENDATION FOR APPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4983a3",
   "metadata": {},
   "source": [
    "The suggestion I have for FB Calibre App improvement are regarding the update of the app and its compatibility. The last update of the app was done in the year 2015. Most of the features in the app are not supported on latest Android devices. For someone with latest Android device, it will be quite difficult to access or use the app. The app has to get updated to be compatible with latest devices and latest operating systems. \n",
    "\n",
    "The second suggestion I have is based on the app asking the users to install extra plugins and preventing them from connecting to catalogues. One of the app descriptions mentions that this app an OPDS, but on the contrary, it doesn't support all the digital media. They should fix the glitches that occur and provide features to be already exisiting in the app instead of expecting the users to install them. \n",
    "\n",
    "Along with the aforementioned points, I came up with these suggestions by looking at the app's F-droid page, where the date of issues resolved were in 2014. Similarly, the Google Play store's page also dispalyed the last update to be in 2015. Since then, the app has not updated. I also noticed that there was an issue on the GitHub page asking whether the repository is still supported. So, from all these points and along with the user reviews (1 star, 2 star), I decided to come up with these suggestions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2317ac3f",
   "metadata": {},
   "source": [
    "# TASK 5: GITHUB COMMITS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc605ab",
   "metadata": {},
   "source": [
    "Link 1: https://github.com/geometer/FBReaderJ-plugin-local-opds-scanner/issues/5#issue-1197901417\n",
    "\n",
    "Link 2: https://github.com/geometer/FBReaderJ-plugin-local-opds-scanner/issues/6#issue-1197908248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532c342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
